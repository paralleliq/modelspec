{
  "ModelSpec: Minimal": {
    "prefix": "modelspec-minimal",
    "description": "Minimal ModelSpec (start here)",
    "body": [
      "apiVersion: piqc.ai/v1alpha1",
      "kind: ModelSpec",
      "",
      "metadata:",
      "  name: ${1:model-name}",
      "  version: \"${2:0.1}\"",
      "  description: \"${3:Short description}\"",
      "",
      "spec:",
      "  identity:",
      "    model:",
      "      id: \"${4:model-id}\"",
      "      task: \"${5:chat-completion}\"",
      "      framework: \"${6:vllm}\"",
      "      precision: \"${7:fp16}\"",
      "  runtime:",
      "    accelerator:",
      "      vendor: \"${8:nvidia}\"",
      "      type: \"${9:A100-80GB}\"",
      "      count: ${10:1}"
    ]
  },

  "ModelSpec: vLLM Serving (K8s-ready)": {
    "prefix": "modelspec-vllm-serving",
    "description": "vLLM serving spec with probes, timeouts, and scaling skeleton",
    "body": [
      "apiVersion: piqc.ai/v1alpha1",
      "kind: ModelSpec",
      "",
      "metadata:",
      "  name: ${1:llm-vllm-prod}",
      "  version: \"${2:0.1}\"",
      "  description: \"${3:Production vLLM deployment}\"",
      "  labels:",
      "    team: \"${4:ml-platform}\"",
      "    env: \"${5:prod}\"",
      "",
      "spec:",
      "  identity:",
      "    model:",
      "      id: \"${6:llama-2-70b-chat}\"",
      "      family: \"${7:llama-2}\"",
      "      task: \"${8:chat-completion}\"",
      "      framework: \"vllm\"",
      "      precision: \"${9:fp16}\"",
      "      artifacts:",
      "        modelUri: \"${10:s3://bucket/path/to/weights/}\"",
      "        tokenizerUri: \"${11:s3://bucket/path/to/tokenizer/}\"",
      "",
      "  runtime:",
      "    accelerator:",
      "      vendor: \"${12:nvidia}\"",
      "      type: \"${13:A100-80GB}\"",
      "      count: ${14:1}",
      "    batch:",
      "      maxBatchSize: ${15:16}",
      "      maxSequenceLengthTokens: ${16:4096}",
      "    resources:",
      "      cpuCores: ${17:8}",
      "      memoryGb: ${18:64}",
      "",
      "  operations:",
      "    serving:",
      "      protocol: \"http\"",
      "      port: ${19:8000}",
      "      readinessProbe:",
      "        path: \"/health\"",
      "        timeoutSeconds: ${20:5}",
      "      livenessProbe:",
      "        path: \"/health\"",
      "        timeoutSeconds: ${21:5}",
      "      maxConcurrency: ${22:32}",
      "      timeoutSeconds: ${23:60}",
      "",
      "    scaling:",
      "      minReplicas: ${24:1}",
      "      maxReplicas: ${25:5}",
      "      strategy: \"${26:reactive}\""
    ]
  },

  "ModelSpec: RAG Pipeline (Dependencies)": {
    "prefix": "modelspec-rag-pipeline",
    "description": "RAG pipeline skeleton with dependencies (embedder, retriever, reranker, guardrails)",
    "body": [
      "apiVersion: piqc.ai/v1alpha1",
      "kind: ModelSpec",
      "",
      "metadata:",
      "  name: ${1:rag-pipeline-prod}",
      "  version: \"${2:0.1}\"",
      "  description: \"${3:RAG pipeline with dependencies}\"",
      "",
      "spec:",
      "  identity:",
      "    model:",
      "      id: \"${4:rag-app}\"",
      "      task: \"${5:rag}\"",
      "      framework: \"${6:custom}\"",
      "",
      "  pipeline:",
      "    preprocess:",
      "      steps:",
      "        - name: \"normalize-text\"",
      "          type: \"text_normalization\"",
      "          enabled: true",
      "    postprocess:",
      "      steps:",
      "        - name: \"strip-metadata\"",
      "          type: \"text_filter\"",
      "          enabled: true",
      "",
      "    dependencies:",
      "      - id: \"embedder\"",
      "        role: \"custom\"",
      "        specRef: \"${7:./deps/embedder.modelspec.yaml}\"",
      "        required: true",
      "        interface:",
      "          inputType: \"text\"",
      "          outputType: \"vector\"",
      "          maxLatencyMs: ${8:50}",
      "",
      "      - id: \"retriever\"",
      "        role: \"custom\"",
      "        specRef: \"${9:./deps/retriever.modelspec.yaml}\"",
      "        required: true",
      "        interface:",
      "          inputType: \"vector\"",
      "          outputType: \"documents\"",
      "          maxLatencyMs: ${10:80}",
      "",
      "      - id: \"reranker\"",
      "        role: \"reranker\"",
      "        specRef: \"${11:./deps/reranker.modelspec.yaml}\"",
      "        required: false",
      "        interface:",
      "          inputType: \"documents\"",
      "          outputType: \"ranked_documents\"",
      "          maxLatencyMs: ${12:60}",
      "",
      "      - id: \"input-guardrail\"",
      "        role: \"guardrail\"",
      "        specRef: \"${13:./deps/guardrail-input.modelspec.yaml}\"",
      "        required: false",
      "        interface:",
      "          inputType: \"text\"",
      "          outputType: \"filtered_text\"",
      "          maxLatencyMs: ${14:30}"
    ]
  }
}
